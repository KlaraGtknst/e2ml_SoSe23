{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Statistical Hypothesis Testing II\n",
    "\n",
    "In this notebook, we will implement and apply **statistical hypothesis tests** to make inferences about risks of learning algorithms.\n",
    "\n",
    "At the start, we will compare two learning algorithms on one domain via the paired $t$-test.\n",
    "\n",
    "Subsequently, we will compare the two learning algorithm across multiple domains via the Wilcoxon signed-rank test.\n",
    "\n",
    "### **Table of Contents**\n",
    "1. [Paired $t$-test](#paired-t-test)\n",
    "2. [Wilcoxon Signed-rank Test](#wilcoxon-signed-rank-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T08:31:37.548145500Z",
     "start_time": "2023-07-07T08:31:36.233899500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klara\\anaconda3\\envs\\e2ml-env\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\klara\\anaconda3\\envs\\e2ml-env\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\klara\\anaconda3\\envs\\e2ml-env\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Paired $t$-test** <a class=\"anchor\" id=\"paired-t-test\"></a>\n",
    "\n",
    "We implement the function [`t_test_paired`](../e2ml/evaluation/_paired_tests.py) in the [`e2ml.evaluation`](../e2ml/evaluation) subpackage. Once, the implementation has been completed, we check it for varying types of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T08:35:41.877021300Z",
     "start_time": "2023-07-07T08:35:41.544371800Z"
    }
   },
   "outputs": [],
   "source": [
    "from e2ml.evaluation import t_test_paired\n",
    "r_1 = np.round(stats.norm.rvs(loc=0.1, scale=0.03, size=40, random_state=0), 2)\n",
    "r_2 = np.round(stats.norm.rvs(loc=0.12, scale=0.03, size=40, random_state=1), 2)\n",
    "mu_0 = 0\n",
    "t_statistic, p = t_test_paired(sample_data_1=r_1, sample_data_2=r_2, mu_0=mu_0, test_type=\"right-tail\")\n",
    "assert np.round(t_statistic, 4) == -1.4731 , 'The paired t-test statistic must be ca. -1.4731.' \n",
    "assert np.round(p, 4) == 0.9256, 'The p-value must be ca. 0.9256 for the one-sided right-tail test.' \n",
    "t_statistic, p = t_test_paired(sample_data_1=r_1, sample_data_2=r_2, mu_0=mu_0, test_type=\"left-tail\")\n",
    "assert np.round(t_statistic, 4) == -1.4731 , 'The paired t-test statistic must be ca. -1.4731.' \n",
    "assert np.round(p, 4) == 0.0744, 'The p-value must be ca. 0.0744 for the one-sided left-tail test.' \n",
    "t_statistic, p = t_test_paired(sample_data_1=r_1, sample_data_2=r_2, mu_0=mu_0, test_type=\"two-sided\")\n",
    "assert np.round(t_statistic, 4) == -1.4731 , 'The paired t-test statistic must be ca. -1.4731.' \n",
    "assert np.round(p, 4) == 0.1487, 'The p-value must be ca. 0.1487 for the two-sided test.' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to check whether a *support vector classifier* (SVC) significantly outperforms a *Gaussian process classifier* (GPC) on the data set breast cancer, where we use the zero-one loss as performance measure and the paired $t$-test with $\\alpha=0.01$. Design and perform the corresponding evaluation study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T08:59:36.662426100Z",
     "start_time": "2023-07-07T08:59:35.420205300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klara\\AppData\\Local\\Temp\\ipykernel_14604\\3321032782.py:12: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sample_indices = np.arange(len(y), dtype=np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.013888888888888888, 0.07042253521126761, 0.014084507042253521, 0.014084507042253521, 0.056338028169014086, 0.028169014084507043, 0.056338028169014086, 0.014084507042253521]\n",
      "[0.027777777777777776, 0.056338028169014086, 0.04225352112676056, 0.0, 0.028169014084507043, 0.014084507042253521, 0.04225352112676056, 0.0]\n",
      "H_0 not rejected (lack of evidence): Uncear if the SVC does significantly outperform the GPC with p-value 0.157 (alpha=0.01).\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from e2ml.evaluation import cross_validation\n",
    "from e2ml.preprocessing import StandardScaler\n",
    "from e2ml.evaluation import zero_one_loss\n",
    "\n",
    "# load data\n",
    "X,y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# create folds\n",
    "sample_indices = np.arange(len(y), dtype=np.int)\n",
    "n_folds = 8 # bei kleinem Datensatz, sollten es nicht zu viele folds sein\n",
    "train, test = cross_validation(sample_indices, n_folds=n_folds, y=y, random_state=0)\n",
    "\n",
    "# set up classifiers and prepare result risk list\n",
    "risk_gpc = []\n",
    "risk_svc = []\n",
    "\n",
    "# loop over folds\n",
    "for train_, test_ in zip(train, test): # index list of train and test sets\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X[train_])    # fit scaler on training data\n",
    "    X_train = scaler.transform(X[train_])       # scale training data\n",
    "    X_test = scaler.transform(X[test_])         # scale test data\n",
    "\n",
    "    gpc = GaussianProcessClassifier(random_state=0)\n",
    "    svc = SVC(random_state=0)\n",
    "\n",
    "    # compute performance differences\n",
    "    gpc.fit(X_train, y[train_])\n",
    "    svc.fit(X_train, y[train_])\n",
    "\n",
    "    # predict on test data\n",
    "    y_gpc = gpc.predict(X_test)\n",
    "    y_svc = svc.predict(X_test)\n",
    "\n",
    "    # compute zero-one loss\n",
    "    loss_gpc = zero_one_loss(y[test_], y_gpc)\n",
    "    loss_svc = zero_one_loss(y[test_], y_svc)\n",
    "\n",
    "    # save results of fold\n",
    "    risk_gpc.append(loss_gpc)\n",
    "    risk_svc.append(loss_svc)\n",
    "\n",
    "# TODO: falsche Werte\n",
    "print(risk_gpc)\n",
    "print(risk_svc)\n",
    "# perform paired t-test to compare the performance of the classifiers\n",
    "alpha = 0.01\n",
    "# outperform -> losses of differences -> right tail test\n",
    "t_statistic, p = t_test_paired(sample_data_1=risk_gpc, sample_data_2=risk_svc, mu_0=0, test_type=\"right-tail\")\n",
    "if p < alpha:\n",
    "    print(\"H_0 rejected: The SVC significantly outperforms the GPC with p-value {} (alpha={}).\".format(np.round(p,3), alpha))\n",
    "else:\n",
    "    print(\"H_0 not rejected (lack of evidence): Uncear if the SVC does significantly outperform the GPC with p-value {} (alpha={}).\".format(np.round(p,3), alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Questions:**\n",
    "1. (a) What are possible issues of your conducted evaluation study?\n",
    "   \n",
    "   bei kleinem Datensatz, sollten es nicht zu viele folds sein\n",
    "   overlap training set folds -> nicht independent (test sets sind idependent)\n",
    "   wenig folds -> zero/one loss normalverteilt, aber wenige Daten\n",
    "   viele folds -> zero/one loss nicht normalverteilt\n",
    "   default Parameter -> H_1 ist eine krasse Aussage, wenn man nur eine Parameterkombination testet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Wilcoxon Signed-rank Test** <a class=\"anchor\" id=\"wilcoxon-signed-rank-test\"></a>\n",
    "\n",
    "We implement the function [`wilcoxon_signed_rank_test`](../e2ml/evaluation/_paired_tests.py) in the [`e2ml.evaluation`](../e2ml/evaluation) subpackage. Once, the implementation has been completed, we check it for varying types of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from e2ml.evaluation import wilcoxon_signed_rank_test\n",
    "\n",
    "# Test for exact computation.\n",
    "r_1 = stats.norm.rvs(loc=0.1, scale=0.03, size=10, random_state=0)\n",
    "r_2 = stats.norm.rvs(loc=0.15, scale=0.03, size=10, random_state=1)\n",
    "d = r_2 - r_1\n",
    "w_statistic, p = wilcoxon_signed_rank_test(sample_data_1=d, test_type=\"right-tail\")\n",
    "assert w_statistic == 47 , 'The positive rank sum statistic must be 47.' \n",
    "assert np.round(p, 4) == 0.0244, 'The p-value must be ca. 0.0244 for the one-sided right-tail test.' \n",
    "w_statistic, p = wilcoxon_signed_rank_test(sample_data_1=d, test_type=\"left-tail\")\n",
    "assert w_statistic == 47 , 'The positive rank sum statistic must be 47.' \n",
    "assert np.round(p, 4) == 0.9814, 'The p-value must be ca. 0.9814 for the one-sided left-tail test.' \n",
    "w_statistic, p = wilcoxon_signed_rank_test(sample_data_1=d, test_type=\"two-sided\")\n",
    "assert w_statistic == 47 , 'The positive rank sum statistic must be 47.' \n",
    "assert np.round(p, 4) == 0.0488, 'The p-value must be ca. 0.0488 for the two-sided test.' \n",
    "\n",
    "# Test for approximative computation.\n",
    "r_1 = stats.norm.rvs(loc=2, scale=0.3, size=100, random_state=0)\n",
    "r_2 = stats.norm.rvs(loc=2.1, scale=0.3, size=100, random_state=1)\n",
    "d = r_2 - r_1\n",
    "w_statistic, p = wilcoxon_signed_rank_test(sample_data_1=d, test_type=\"right-tail\")\n",
    "assert w_statistic == 3303 , 'The positive rank sum statistic must be 3303.' \n",
    "assert np.round(p, 4) == 0.0037, 'The p-value must be ca. 0.0037 for the one-sided right-tail test.' \n",
    "w_statistic, p = wilcoxon_signed_rank_test(sample_data_1=d, test_type=\"left-tail\")\n",
    "assert w_statistic == 3303 , 'The positive rank sum statistic must be 3303.' \n",
    "assert np.round(p, 4) == 0.9963, 'The p-value must be ca. 0.9963 for the one-sided left-tail test.' \n",
    "w_statistic, p = wilcoxon_signed_rank_test(sample_data_1=d, test_type=\"two-sided\")\n",
    "assert w_statistic == 3303 , 'The positive rank sum statistic must be 3303.' \n",
    "assert np.round(p, 4) == 0.0075, 'The p-value must be ca. 0.0075 for the two-sided test.' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to check whether a *support vector classifier* (SVC) significantly outperforms a *Gaussian process classifier* (GPC) on ten articially generated data sets, where we use the zero-one loss as performance measure and the paired $t$-test with $\\alpha=0.01$. Design and perform the corresponding evaluation study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Create 10 articial data sets.\n",
    "data_sets = []\n",
    "n_classes_list = np.arange(2, 12)\n",
    "for n_classes in n_classes_list:\n",
    "    X, y = make_classification(\n",
    "        n_samples=500, n_classes=n_classes, class_sep=2, n_informative=10, random_state=n_classes\n",
    "    )\n",
    "    data_sets.append((X, y))\n",
    "\n",
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Questions:**\n",
    "2. (a) What are possible issues of your conducted evaluation study?\n",
    "   \n",
    "   TODO\n",
    "   TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
